{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0V479m_FZWWn"
   },
   "source": [
    "# Importy\n",
    "Zaczymamy od zaimportowania potrzebnych bibliotek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PpnRZ1gTUQ7P"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q4XdcYL_s8_v"
   },
   "outputs": [],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gWF0BIPiSZYc"
   },
   "source": [
    "## Wczytanie danych\n",
    "Na początek pobobieramy i rozpakowujemy dane."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J-ZfT9XfUUHi"
   },
   "outputs": [],
   "source": [
    "zip_path = tf.keras.utils.get_file(\n",
    "    origin='https://storage.googleapis.com/tensorflow/tf-keras-datasets/jena_climate_2009_2016.csv.zip',\n",
    "    fname='jena_climate_2009_2016.csv.zip',\n",
    "    extract=True)\n",
    "csv_path, _ = os.path.splitext(zip_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "22gymVGFSjZV"
   },
   "source": [
    "Pobrany przez nas plik zawiera pomiary różnych parametrów pogodowych. Spórzmy na kilka pierwszysch wpisów aby wyrobić sobie intuicję."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vy7Fk3hqStsr"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(csv_path)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ceAJzXdZS3sy"
   },
   "source": [
    "Widzimy, że dane zawierają wiele parmetrów. Naszym celem będzie predykcja temperatury (T (degC)). W tym celu będziemy używać nie tylko temperatury historycznej, ale także innych zmierzonych wartości.\n",
    "\n",
    "Dane były zbieranie z okresem 10 minut. Możemy powiedzieć że częstotliwość próbkowanania wynosi 5 razy na godzinę. W tym przypadku jest to ważne, gdyż temperatura ma charakter ciągły i pomiar odbywa się co pewien czas. W przypadku danych dyskretnych (np. sekwencja DNA, tekst) - nie mamy do czynienia z czasem pobrania próbki - po prostu mamy kolejne, następujące po sobie wartości.\n",
    "\n",
    "Na nasze potrzeby będziemy potrzebowali danych próbkowanych co godzinę. Dlatego najpierw wybierzmy odpowiednie wiersze:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rozcN442S3R7"
   },
   "outputs": [],
   "source": [
    "df = df[5::6].copy()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NpbYF4TwUDW_"
   },
   "source": [
    "## EDA i preprocessing\n",
    "Przyjrzyjmy sie rozkładowi danych:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IEOt-AFGU6r7"
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ljmWaNvcUPs2"
   },
   "source": [
    "### Pytanie\n",
    "Czy wiesz dlaczego wiatr jest podany w dwóch kolumnach? (wd (deg) oraz wv (m/s)). Pytanie może być bardzo trudnie jeżeli nigdy nie miałeś_aś styczności z takimi danymi.\n",
    "\n",
    "### Pytanie\n",
    "W jaki inny sposób możemy opisać dane nt. siły i kierunku wiatru? Jaki jest problem z obecną reprezentacją?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m97ggMWiVFKI"
   },
   "source": [
    "## Poprawianie outlierów. \n",
    "\n",
    "Wartość -9999 jest najprawdopodbniej błędna. Zamieńmy ją na zero.\n",
    "\n",
    "### Pytanie\n",
    "Dlaczego nie chcemy po prostu usunąć tych rekordów?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yBP5ozOPVeKZ"
   },
   "outputs": [],
   "source": [
    "# proszę zamienić wszystkie rekordy poniżej 0 dla kolumny 'wv (m/s)' i 'max. wv (m/s)' na wartość 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PBmQvlBxs8_0"
   },
   "outputs": [],
   "source": [
    "df[['wv (m/s)', 'max. wv (m/s)']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xYfZGTmEWXKP"
   },
   "source": [
    "Wiemy już, że azymut nie jest dobrą cechą. Najprościej będzie się jej pozbyć. Przy okazji usuńmy kolumnę ze stemplem czasowym. Nie będziemy go używać w modelu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GcEf0G2iVJfI"
   },
   "outputs": [],
   "source": [
    "# proszę usunąć kolumny 'wd (deg)' i 'Date Time' z naszej ramki danych\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7mkCBnS9Z3Cx"
   },
   "source": [
    "## Pytanie - Fearture engineering\n",
    "\n",
    "Powyższe kolumny mogłby nie zostać usunięte ale jakoś zamienione/przetransformowane - czy macie pomysł jak?\n",
    "\n",
    "### Dla chętnych\n",
    "Przeprowadzić Feature Engineering i spróbować poniższego modelu na rozszerzonych danych. Można skorzystać z pomysłów podanych pod tym linkiem: https://www.tensorflow.org/tutorials/structured_data/time_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e4U_IezzavCL"
   },
   "source": [
    "# Podział na zbiory treningowy/walidacyjny i testowy\n",
    "\n",
    "Podzielmy dane na zbiory train/val/test. Zwykle podziału dokonujemy losowo, tym razem jest inaczej. Pierwsze 70% trafi do zbiory treningowego, kolejne 15% do walidacyjnego a ostatne 15% do testowego. Zapewni to bardziej wiarygodną ewaluację - model testujemy na danych późniejszych niż treningowe. Dodatkowo w ten sposób będziemy mieli zapewnioną spójność wygenerowanych okien - o co chodzi dowiesz się wkrótce ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qFp4hT-hV5nF"
   },
   "outputs": [],
   "source": [
    "column_indices = {name: i for i, name in enumerate(df.columns)}\n",
    "\n",
    "# proszę zwrócić uwagę, że nie możemy użyć train_test_split gdyż potasowałby dane\n",
    "# a my musimy zachować kolejność naszych pomiarów\n",
    "dset_len = len(df)\n",
    "df_train = df.iloc[0:int(dset_len*0.7)]\n",
    "df_val = df.iloc[int(dset_len*0.7):int(dset_len*0.85)]\n",
    "df_test = df.iloc[int(dset_len*0.85):]\n",
    "\n",
    "num_features = df.shape[1]\n",
    "len(df_train), len(df_val), len(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Bp7Kq81bsjT"
   },
   "source": [
    "## Normalizacja/standaryzacja\n",
    "\n",
    "Sieć neuronowa potrzebuje danych numerycznych w standardowej postaci. Tzn, średnia każdej cechy powinna wynosić zero a jej odchylenie standardowe jeden. Dobra wiadomość jest taka, że dowolne dane możemy przekształcić do takiej formy przy użyciu wzoru:\n",
    "$$ z= \\frac{x-μ}{σ}$$\n",
    "\n",
    "UWAGA, średnią i odchylenie obliczamy ze zbioru treningowego! To bardzo ważne, inaczej mamy wyciek ze zbiorów val/test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VuLw71EwhcUC"
   },
   "outputs": [],
   "source": [
    "# proszę wykonać standaryzację (ręcznie lub przez sklearn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fJHPFN3Zh3ik"
   },
   "outputs": [],
   "source": [
    "df_train.describe().round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zh3D74IFs8_3"
   },
   "outputs": [],
   "source": [
    "df_val.describe().round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xXTUB67we4r6"
   },
   "source": [
    "Przyjrzyjmy sie jak rozład wygląda teraz:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WqO1kmgvh5sl"
   },
   "outputs": [],
   "source": [
    "ax = sns.violinplot(x='variable', y='value', data=df_train.melt())\n",
    "ax.grid()\n",
    "_ = ax.set_xticklabels(df_train.keys(), rotation=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dydttSgOe8oN"
   },
   "source": [
    "To samo dla zbioru walidacyjnego"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BpsJwEMkfCX2"
   },
   "outputs": [],
   "source": [
    "ax = sns.violinplot(x='variable', y='value', data=df_val.melt())\n",
    "ax.grid()\n",
    "_ = ax.set_xticklabels(df_val.keys(), rotation=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mETQTs8JfTzT"
   },
   "source": [
    "## Zapisanie zbiorów\n",
    "\n",
    "Mamy gotowe dane, teraz wystarczy je zapisać."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "26LvF8Lzfg_6"
   },
   "outputs": [],
   "source": [
    "df_train.to_csv('temp_train.csv')\n",
    "df_val.to_csv('temp_val.csv')\n",
    "df_test.to_csv('temp_test.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p1k6BVqlfwkg"
   },
   "source": [
    "# Przygotowamie danych do użycia w modelu\n",
    "\n",
    "Nadal nie wiemy jak zakodować dane tak aby użyć ich w modelu. To za chwilę się zmiemi ;) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TeC5AF-6s_In"
   },
   "outputs": [],
   "source": [
    "# kod pochodzi z https://www.tensorflow.org/tutorials/structured_data/time_series\n",
    "\n",
    "class WindowGenerator():\n",
    "    \"\"\"\n",
    "    Generator posłuży nam do generowania tzw okien na których bedziemy pracować. \n",
    "    Okien tzn fragmentów sekwencji które trafią do modelu\n",
    "    \"\"\"\n",
    "    def __init__(self, input_width, label_width, shift,\n",
    "                 train_df=df_train, val_df=df_val, test_df=df_test,\n",
    "                 label_columns=None):\n",
    "        \"\"\"\n",
    "        input_width - ile elementów ma liczyć sekwencja wejściowa?\n",
    "        label_width - ile elementów ma liczyć sekwejcha wyjściowa? \n",
    "                      innymi słowy - czy przewidujemy jedną czy więcej\n",
    "                      wartości na wyjściu?\n",
    "        shift - o ile output ma być przesunięty względem inputu? Np czy przewidujemy temperaturę za godzinę czy za 24h\n",
    "        \"\"\"\n",
    "        # Store the raw data.\n",
    "        self.train_df = train_df\n",
    "        self.val_df = val_df\n",
    "        self.test_df = test_df\n",
    "        # Work out the label column indices.\n",
    "        self.label_columns = label_columns\n",
    "        if label_columns is not None:\n",
    "            self.label_columns_indices = {name: i for i, name in\n",
    "                                        enumerate(label_columns)}\n",
    "        self.column_indices = {name: i for i, name in\n",
    "                               enumerate(train_df.columns)}\n",
    "        # Work out the window parameters.\n",
    "        self.input_width = input_width\n",
    "        self.label_width = label_width\n",
    "        self.shift = shift\n",
    "        self.total_window_size = input_width + shift\n",
    "        self.input_slice = slice(0, input_width)\n",
    "        self.input_indices = np.arange(self.total_window_size)[self.input_slice]\n",
    "        self.label_start = self.total_window_size - self.label_width\n",
    "        self.labels_slice = slice(self.label_start, None)\n",
    "        self.label_indices = np.arange(self.total_window_size)[self.labels_slice]\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return '\\n'.join([\n",
    "            f'Total window size: {self.total_window_size}',\n",
    "            f'Input indices: {self.input_indices}',\n",
    "            f'Label indices: {self.label_indices}',\n",
    "            f'Label column name(s): {self.label_columns}'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XqBGh46kiiPP"
   },
   "outputs": [],
   "source": [
    "def split_window(self, features):\n",
    "    inputs = features[:, self.input_slice, :]\n",
    "    labels = features[:, self.labels_slice, :]\n",
    "    if self.label_columns is not None:\n",
    "        labels = tf.stack(\n",
    "            [labels[:, :, self.column_indices[name]] for name in self.label_columns],\n",
    "            axis=-1)\n",
    "    # Slicing doesn't preserve static shape information, so set the shapes\n",
    "    # manually. This way the `tf.data.Datasets` are easier to inspect.\n",
    "    inputs.set_shape([None, self.input_width, None])\n",
    "    labels.set_shape([None, self.label_width, None])\n",
    "    return inputs, labels\n",
    "\n",
    "WindowGenerator.split_window = split_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r3j28RX4o9Vw"
   },
   "outputs": [],
   "source": [
    "def plot(self, model=None, plot_col='T (degC)', max_subplots=3):\n",
    "    inputs, labels = self.example\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plot_col_index = self.column_indices[plot_col]\n",
    "    max_n = min(max_subplots, len(inputs))\n",
    "    for n in range(max_n):\n",
    "        plt.subplot(max_n, 1, n+1)\n",
    "        plt.ylabel(f'{plot_col} [normed]')\n",
    "        plt.plot(self.input_indices, inputs[n, :, plot_col_index],\n",
    "                 label='Inputs', marker='.', zorder=-10)\n",
    "        if self.label_columns:\n",
    "            label_col_index = self.label_columns_indices.get(plot_col, None)\n",
    "        else:\n",
    "            label_col_index = plot_col_index\n",
    "        if label_col_index is None:\n",
    "            continue\n",
    "        plt.scatter(self.label_indices, labels[n, :, label_col_index],\n",
    "                    edgecolors='k', label='Labels', c='#2ca02c', s=64)\n",
    "        if model is not None:\n",
    "            predictions = model(inputs)\n",
    "            if len(predictions.shape) == 2:\n",
    "                predictions = tf.expand_dims(predictions,1)\n",
    "            plt.scatter(self.label_indices, predictions[n, :, label_col_index],\n",
    "                        marker='X', edgecolors='k', label='Predictions',\n",
    "                        c='#ff7f0e', s=64)\n",
    "        if n == 0:\n",
    "            plt.legend()\n",
    "    plt.xlabel('Time [h]')\n",
    "\n",
    "WindowGenerator.plot = plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UIMO2WmFp235"
   },
   "outputs": [],
   "source": [
    "def make_dataset(self, data):\n",
    "    data = np.array(data, dtype=np.float32)\n",
    "    ds = tf.keras.utils.timeseries_dataset_from_array(\n",
    "        data=data,\n",
    "        targets=None,\n",
    "        sequence_length=self.total_window_size,\n",
    "        sequence_stride=1,\n",
    "        shuffle=True,\n",
    "        batch_size=32,)\n",
    "    ds = ds.map(self.split_window)\n",
    "    return ds\n",
    "\n",
    "WindowGenerator.make_dataset = make_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5TSkGyHn1gVM"
   },
   "outputs": [],
   "source": [
    "@property\n",
    "def train(self):\n",
    "    return self.make_dataset(self.train_df)\n",
    "\n",
    "@property\n",
    "def val(self):\n",
    "    return self.make_dataset(self.val_df)\n",
    "\n",
    "@property\n",
    "def test(self):\n",
    "    return self.make_dataset(self.test_df)\n",
    "\n",
    "@property\n",
    "def example(self):\n",
    "    \"\"\"Get and cache an example batch of `inputs, labels` for plotting.\"\"\"\n",
    "    result = getattr(self, '_example', None)\n",
    "    if result is None:\n",
    "        # No example batch was found, so get one from the `.train` dataset\n",
    "        result = next(iter(self.train))\n",
    "        # And cache it for next time\n",
    "        self._example = result\n",
    "    return result\n",
    "\n",
    "WindowGenerator.train = train\n",
    "WindowGenerator.val = val\n",
    "WindowGenerator.test = test\n",
    "WindowGenerator.example = example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oWrs0jLF1m__"
   },
   "outputs": [],
   "source": [
    "# przykładowe okno - predykcja jednej wartości temperaturny na podstawie ostatnich 12h\n",
    "next_in_12_h = WindowGenerator(input_width=12, label_width=1, shift=1, label_columns=['T (degC)'])\n",
    "print(next_in_12_h)\n",
    "next_in_12_h.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-ry9fk4M1uWb"
   },
   "outputs": [],
   "source": [
    "# przykładowe okno - predykcja jednej wartości temperaturny za 24h na podstawie ostatnich 24h\n",
    "lookahead_24h = WindowGenerator(input_width=24, label_width=1, shift=24, label_columns=['T (degC)'])\n",
    "print(lookahead_24h)\n",
    "lookahead_24h.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "emn_vTX818wY"
   },
   "outputs": [],
   "source": [
    "# przykładowe okno - predykcja następnych 24h wartości temperaturny na podstawie ostatnich 48h\n",
    "continous_24h = WindowGenerator(input_width=48, label_width=24, shift=24, label_columns=['T (degC)'])\n",
    "print(continous_24h)\n",
    "continous_24h.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JFcd4L4p2IVu"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nK8Pnp8x3HqZ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y7AoZuXN1uwO"
   },
   "source": [
    "## Pytanie\n",
    "\n",
    "Jaki baseline możemy wymyślić?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YmcdGScu9T4l"
   },
   "outputs": [],
   "source": [
    "single_step_window = WindowGenerator(\n",
    "    input_width=1, label_width=1, shift=1,\n",
    "    label_columns=['T (degC)'])\n",
    "single_step_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XuEllgLn8jj4"
   },
   "outputs": [],
   "source": [
    "class Baseline(tf.keras.Model):\n",
    "    def __init__(self, label_index=None):\n",
    "        super().__init__()\n",
    "        self.label_index = label_index\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        if self.label_index is None:\n",
    "            return inputs\n",
    "        result = inputs[:, :, self.label_index]\n",
    "        return result[:, :, tf.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VPqdXrte8mmb"
   },
   "outputs": [],
   "source": [
    "# baseline - prosty (naiwny) model predykujący, że za godzinę będzie dokładnie \n",
    "# taka sama temperatura, jaka jest akutalnie\n",
    "baseline = Baseline(label_index=column_indices['T (degC)'])\n",
    "\n",
    "baseline.compile(loss=tf.keras.losses.MeanSquaredError(),\n",
    "                 metrics=[tf.keras.metrics.MeanAbsoluteError()])\n",
    "\n",
    "val_performance = {}\n",
    "performance = {}\n",
    "val_performance['Baseline'] = baseline.evaluate(single_step_window.val)\n",
    "performance['Baseline'] = baseline.evaluate(single_step_window.test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3fPqmN0X8soI"
   },
   "outputs": [],
   "source": [
    "wide_window = WindowGenerator(\n",
    "    input_width=24, label_width=24, shift=1,\n",
    "    label_columns=['T (degC)'])\n",
    "\n",
    "wide_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qgr59Wa587dt"
   },
   "outputs": [],
   "source": [
    "wide_window.plot(baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5EvzgFMRR2Fs"
   },
   "source": [
    "# Modelowanie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aZnbF2U8Svnr"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import SimpleRNN, Dense\n",
    "from tensorflow.keras.losses import MeanAbsoluteError, MeanSquaredError\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P-b_CjCaEWt4"
   },
   "source": [
    "Możemy wykorzystać zarówno mse jak i mae - oba nadają się do regresji. MAE będzie przykładał mniejszą wagę do dużych błędów. To które wybieramy zależy od tego na czym nam zależy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oi2r-KJkUb2y"
   },
   "source": [
    "$ mse = (y - \\hat{y})^2 $\n",
    "\n",
    "\n",
    "$ mae = |y - \\hat{y}| $\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PIZUtJ96R0WB"
   },
   "outputs": [],
   "source": [
    "next_in_12_h = WindowGenerator(input_width=12, label_width=1, shift=1, label_columns=['T (degC)'])\n",
    "print(next_in_12_h)\n",
    "next_in_12_h.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "II5gAqvoR1Ry"
   },
   "outputs": [],
   "source": [
    "# PROSZĘ UZUPEŁNIĆ KOD\n",
    "rnn_model = keras.models.Sequential()\n",
    "# proszę dodać następujące warstwy sieci:\n",
    "# - warstwę SimpleRNN z 32 komórkami (tym razem proszę tutaj nie podawać kształtu wejścia)\n",
    "# - warstwę gęstą z liczbą odpowiadającą wyjściu\n",
    "\n",
    "\n",
    "# proszę wykorzystać metodę `build` i w niej podać odpowiedni kształt wejścia\n",
    "# - pierwszy wymiar odpowiada batchowi ale proszę go ustawić na dowolną wielkość batcha\n",
    "# - drugi odpowiada liczbie kroków w czasie\n",
    "# - trzeci odpowiada liczbie cech zawartych w każdym kroku w czasie\n",
    "\n",
    "\n",
    "rnn_model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jPXxGoAJ0VRV"
   },
   "outputs": [],
   "source": [
    "# proszę określić funkcję kosztu najczęściej używaną w zadaniu regresji\n",
    "criterion = None\n",
    "# zainicjalizować optimizer Adam\n",
    "optim = None\n",
    "\n",
    "#skompilować model 'rnn_model' z optimizerem, funkcją straty oraz metrykami do monitorowania: MAE i MSE\n",
    "\n",
    "\n",
    "# proszę wytrenować model podając odpowiedni generator danych przez 7 epok, również podać odpowiedni generator danych dla walidacji podczas treningu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "poEBQXtpCSh9"
   },
   "outputs": [],
   "source": [
    "next_in_12_h.plot(rnn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j-RprKBZTMVm"
   },
   "outputs": [],
   "source": [
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "plt.plot(train_loss[1:], label='train loss')\n",
    "plt.plot(val_loss[1:], label='val loss')\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fq4gfk40bY05"
   },
   "outputs": [],
   "source": [
    "# możemy też \"zapakować\" powyższy model w klasę aby łatwiej obsługiwać w przyszłości\n",
    "class TemperatureModel(keras.Model): # definiujemy model przez subclassing\n",
    "    def __init__(self, rnn_hidden_size): # hidden size przekazujemy jako parametr modelu\n",
    "        # ofc równie dobrze możemy zahardcodować (i tak generalnie robimy w trakcie kursu)\n",
    "        # żeby oszczędzić trochę czasu na pisaniu \n",
    "        super().__init__(self)\n",
    "        self.rnn = SimpleRNN(rnn_hidden_size) # prosta sieć rnn\n",
    "        self.fc = Dense(1) # jeden neuron na wyjściu (przewidujemy jedną wartość).\n",
    "        # bez aktywacji ponieważ robimy regresję!\n",
    "        \n",
    "    def call(self, inputs, training=False):\n",
    "        x = inputs\n",
    "        x = self.rnn(x, training=training)\n",
    "        x = self.fc(x, training=training)\n",
    "        return x\n",
    "\n",
    "\n",
    "tm = TemperatureModel(32) # model rnn o wielkości 32\n",
    "tm.build(input_shape=[None, 12, 13]) # input batch size x szerokość okna wejściowego (czly seq len - to to samo) x 13 features]\n",
    "\n",
    "tm.summary()\n",
    "\n",
    "\n",
    "criterion = MeanSquaredError() # MSE\n",
    "optim = Adam()\n",
    "\n",
    "tm.compile(optimizer=optim, loss=criterion, metrics=['mae', 'mse']) # do raportowania spojrzymy też na mae\n",
    "\n",
    "history = tm.fit(next_in_12_h.train, epochs=3, validation_data=next_in_12_h.val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EWy6dRbGTZaN"
   },
   "outputs": [],
   "source": [
    "val_performance['TM'] = tm.evaluate(next_in_12_h.val)\n",
    "performance['TM'] = tm.evaluate(next_in_12_h.test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6hihZCN__X95"
   },
   "outputs": [],
   "source": [
    "next_in_12_h.plot(tm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7Mk3g8LP_ddl"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Forecasting_przygotowanie_danych_i_model-plain.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "mlp",
   "language": "python",
   "name": "mlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
