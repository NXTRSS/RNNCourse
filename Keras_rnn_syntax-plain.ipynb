{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RlIvQt0dse4l"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GfVnhMsFtsag"
   },
   "source": [
    "# Generowanie danych\n",
    "\n",
    "Na początek wygenerujmy przykładowe dane. Niech będzie to pomiar pewnej wartości. Dane powinny mieć format 1xTx1 gdzie T to ilośc próbek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ox4ljZWbtpX8"
   },
   "outputs": [],
   "source": [
    "T = 300\n",
    "time = np.linspace(0,10,T)\n",
    "X = 0.2 * time + np.random.randn(T)*0.1  + 0.5 * np.sin(time*1.5)\n",
    "X = np.expand_dims(X, 0)\n",
    "X = np.expand_dims(X, -1)\n",
    "print(X.shape)\n",
    "plt.plot(X[0, :, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TV8YJ0Eiu4lO"
   },
   "source": [
    "## Tworzenie prostej sieci RNN (N:1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sWxKLpo0ubBE"
   },
   "outputs": [],
   "source": [
    "rnn = layers.SimpleRNN(units=64)\n",
    "output = rnn(X)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DYj1DiOC6VPF"
   },
   "source": [
    "## Zadanie: sprawdź wartośc min i max zwróconych wyników. Czy pasują do nieliniowości tanh?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5ojYIyX4uv9X"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EOUQO92j-Sbd"
   },
   "source": [
    "## Klasyfikacja całej sekwencji do jednej z 10 klas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QbqQtpB7-bab"
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "#proszę dodać warstwy:\n",
    "# - warstwa SimpleRNN z liczbą neuronów 64 i odpowiednim kształtem wejścia\n",
    "# - warstwa gęsta z 10 neuronami i najczęstszą funkcją aktywacji na ostatniej warstwie dla klasyfikacji\n",
    "\n",
    "\n",
    "\n",
    "model.summary()\n",
    "output = model(X)\n",
    "print(output.shape)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bG1kF97H6v0C"
   },
   "source": [
    "# Tworzenie warstwy RNN (N:N)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y7Ecvk4Lvk42"
   },
   "outputs": [],
   "source": [
    "rnn = layers.SimpleRNN(units=64, return_sequences=True)\n",
    "output = rnn(X)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vC536ruF7tRs"
   },
   "source": [
    "## Wielowarstwowa sieć RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MZNgvHo9_QCB"
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "#proszę dodać warstwy:\n",
    "# - warstwa SimpleRNN z liczbą neuronów 64 i odpowiednim kształtem wejścia i informacją \n",
    "# aby przekazać w głąb sieci sekwencję\n",
    "# - warstwa SimpleRNN z liczbą neuronów 64\n",
    "\n",
    "\n",
    "model.summary()\n",
    "\n",
    "output = model(X)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ix8zWUAe7iTm"
   },
   "source": [
    "## Zadanie: Skąd wynikają liczby parametrów?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cnH69mFW_y_0"
   },
   "source": [
    "## Klasyfikacja wszystkich elementów sekwencji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QhxKkph_5c8-"
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "\n",
    "# zadeklarować warstwę SimpleRNN z liczbą neuronów 64 i odpowiednim kształtem wejścia i informacją \n",
    "# aby przekazać w głąb sieci sekwencję i odpowiednim kształtem wejścia\n",
    "rnn1 = None\n",
    "\n",
    "# zadeklarować warstwę SimpleRNN z liczbą neuronów 64 i odpowiednim kształtem wejścia i informacją \n",
    "# aby przekazać w głąb sieci sekwencję\n",
    "rnn2 = None\n",
    "\n",
    "#zadeklarować warstwę łączącą/agregującą sekwencję w sieć pełnych połączeń (coś jak flatten przy zdjęciach)\n",
    "# i przekazać do warstwy gęstej z 10 neuronami i najczęstszą funkcją aktywacji \n",
    "# na ostatniej warstwie dla klasyfikacji (hint: TimeDistributed i Dense)\n",
    "fc = None\n",
    "\n",
    "model.add(rnn1)\n",
    "model.add(rnn2)\n",
    "model.add(fc)\n",
    "model.build(input_shape=(None, None, 1))\n",
    "model.summary()\n",
    "\n",
    "output = model(X)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bQAvB0wv6KXh"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPi0fDHT4esQFffCuWEgJhV",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Keras RNN 101 - empty.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "mlp",
   "language": "python",
   "name": "mlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
